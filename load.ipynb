{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "# from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {'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'}\",\n",
    "    # \"HTTP-Referer\": f\"{YOUR_SITE_URL}\", # Optional, for including your app on openrouter.ai rankings.\n",
    "    # \"X-Title\": f\"{YOUR_APP_NAME}\", # Optional. Shows in rankings on openrouter.ai.\n",
    "  },\n",
    "  data=json.dumps({\n",
    "    \"model\": \"meta-llama/llama-3.1-8b-instruct:free\", # Optional\n",
    "    \"messages\": [\n",
    "      { \"role\": \"user\", \"content\": \"What is the meaning of life?\" }\n",
    "    ]\n",
    "    \n",
    "  })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "pc.create_index(\n",
    "    name=\"rag\",\n",
    "    dimension=1536,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'professor': 'Dr. Smith',\n",
       "  'subject': 'Biology',\n",
       "  'stars': 4,\n",
       "  'review': 'Engaging lectures, but tough grader.'},\n",
       " {'professor': 'Prof. Johnson',\n",
       "  'subject': 'Mathematics',\n",
       "  'stars': 5,\n",
       "  'review': 'Excellent at explaining complex concepts.'},\n",
       " {'professor': 'Dr. Lee',\n",
       "  'subject': 'Chemistry',\n",
       "  'stars': 3,\n",
       "  'review': 'Knowledgeable, but moves too fast.'},\n",
       " {'professor': 'Prof. Garcia',\n",
       "  'subject': 'History',\n",
       "  'stars': 4,\n",
       "  'review': 'Passionate about the subject.'},\n",
       " {'professor': 'Dr. Patel',\n",
       "  'subject': 'Computer Science',\n",
       "  'stars': 5,\n",
       "  'review': 'Very helpful during office hours.'},\n",
       " {'professor': 'Prof. Brown',\n",
       "  'subject': 'English Literature',\n",
       "  'stars': 4,\n",
       "  'review': 'Insightful discussions in class.'},\n",
       " {'professor': 'Dr. Wilson',\n",
       "  'subject': 'Physics',\n",
       "  'stars': 3,\n",
       "  'review': 'Difficult exams, but fair.'},\n",
       " {'professor': 'Prof. Taylor',\n",
       "  'subject': 'Psychology',\n",
       "  'stars': 5,\n",
       "  'review': 'Makes the material relatable.'},\n",
       " {'professor': 'Dr. Anderson',\n",
       "  'subject': 'Economics',\n",
       "  'stars': 4,\n",
       "  'review': 'Clear explanations of complex theories.'},\n",
       " {'professor': 'Prof. Martinez',\n",
       "  'subject': 'Sociology',\n",
       "  'stars': 3,\n",
       "  'review': 'Interesting topics, but heavy workload.'},\n",
       " {'professor': 'Dr. Thompson',\n",
       "  'subject': 'Art History',\n",
       "  'stars': 5,\n",
       "  'review': 'Passionate and knowledgeable.'},\n",
       " {'professor': 'Prof. White',\n",
       "  'subject': 'Political Science',\n",
       "  'stars': 4,\n",
       "  'review': 'Encourages critical thinking.'},\n",
       " {'professor': 'Dr. Harris',\n",
       "  'subject': 'Geology',\n",
       "  'stars': 3,\n",
       "  'review': 'Field trips are great, lectures less so.'},\n",
       " {'professor': 'Prof. Clark',\n",
       "  'subject': 'Philosophy',\n",
       "  'stars': 5,\n",
       "  'review': 'Challenging but rewarding classes.'},\n",
       " {'professor': 'Dr. Lewis',\n",
       "  'subject': 'Anthropology',\n",
       "  'stars': 4,\n",
       "  'review': 'Engaging storyteller and educator.'},\n",
       " {'professor': 'Prof. Walker',\n",
       "  'subject': 'Music Theory',\n",
       "  'stars': 3,\n",
       "  'review': 'Knows the subject well, but strict.'},\n",
       " {'professor': 'Dr. Hall',\n",
       "  'subject': 'Environmental Science',\n",
       "  'stars': 5,\n",
       "  'review': 'Inspiring and practical approach.'},\n",
       " {'professor': 'Prof. Young',\n",
       "  'subject': 'Statistics',\n",
       "  'stars': 4,\n",
       "  'review': 'Patient and thorough explanations.'},\n",
       " {'professor': 'Dr. King',\n",
       "  'subject': 'Linguistics',\n",
       "  'stars': 3,\n",
       "  'review': 'Interesting material, but disorganized.'},\n",
       " {'professor': 'Prof. Wright',\n",
       "  'subject': 'Business Ethics',\n",
       "  'stars': 4,\n",
       "  'review': 'Thought-provoking discussions.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = json.load(open(\"reviews.json\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engaging lectures, but tough grader.\n",
      "Excellent at explaining complex concepts.\n",
      "Knowledgeable, but moves too fast.\n",
      "Passionate about the subject.\n",
      "Very helpful during office hours.\n",
      "Insightful discussions in class.\n",
      "Difficult exams, but fair.\n",
      "Makes the material relatable.\n",
      "Clear explanations of complex theories.\n",
      "Interesting topics, but heavy workload.\n",
      "Passionate and knowledgeable.\n",
      "Encourages critical thinking.\n",
      "Field trips are great, lectures less so.\n",
      "Challenging but rewarding classes.\n",
      "Engaging storyteller and educator.\n",
      "Knows the subject well, but strict.\n",
      "Inspiring and practical approach.\n",
      "Patient and thorough explanations.\n",
      "Interesting material, but disorganized.\n",
      "Thought-provoking discussions.\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    print(i[\"review\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m [data[\u001b[39m0\u001b[39m]]\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m review \u001b[39min\u001b[39;00m data:\n\u001b[0;32m----> 6\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49membeddings\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      7\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mreview[\u001b[39m\"\u001b[39;49m\u001b[39mreview\u001b[39;49m\u001b[39m\"\u001b[39;49m], model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-embedding-3-small\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     embedding \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39membedding\n\u001b[1;32m     10\u001b[0m     processed_data\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     11\u001b[0m         {\n\u001b[1;32m     12\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m: embedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         }\n\u001b[1;32m     20\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    116\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[1;32m    117\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    118\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[1;32m    119\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[1;32m    120\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[1;32m    121\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    122\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[1;32m    123\u001b[0m     ),\n\u001b[1;32m    124\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1247\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1256\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1257\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1258\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1259\u001b[0m     )\n\u001b[0;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    936\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 937\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    938\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    939\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    940\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    941\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    942\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    943\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m   1025\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1026\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m   1027\u001b[0m         input_options,\n\u001b[1;32m   1028\u001b[0m         cast_to,\n\u001b[1;32m   1029\u001b[0m         retries,\n\u001b[1;32m   1030\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   1031\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1032\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1035\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1075\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1076\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1077\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1078\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[1;32m   1079\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1080\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1081\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m   1025\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1026\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m   1027\u001b[0m         input_options,\n\u001b[1;32m   1028\u001b[0m         cast_to,\n\u001b[1;32m   1029\u001b[0m         retries,\n\u001b[1;32m   1030\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   1031\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1032\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1035\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1075\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1076\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1077\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1078\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[1;32m   1079\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1080\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1081\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1040\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m   1044\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m   1045\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     retries_taken\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39mget_max_retries(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries) \u001b[39m-\u001b[39m retries,\n\u001b[1;32m   1050\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "client = OpenAI()\n",
    "data = [data[0]]\n",
    "\n",
    "for review in data:\n",
    "    response = client.embeddings.create(\n",
    "        input=review[\"review\"], model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    processed_data.append(\n",
    "        {\n",
    "            \"values\": embedding,\n",
    "            \"id\": review[\"professor\"],\n",
    "            \"metadata\":{\n",
    "                \"review\": review[\"review\"],\n",
    "                \"subject\": review[\"subject\"],\n",
    "                \"stars\": review[\"stars\"],\n",
    "            }\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
